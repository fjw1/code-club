{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importing modules (\"libraries\")\n",
    "from __future__ import division  # Not needed for Python 3.x\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import log\n",
    "from scipy.optimize import fminbound\n",
    "from scipy import interp\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Function Iteration part 1\n",
    "\n",
    "\n",
    "Today we are going to see Value Function Iteration.\n",
    "\n",
    "This is an algorithm that solves for dynamic consumption problems - bellman equations. Roughly speaking, if you can write down your problem as a Bellman equation, you can solve it by VFI.\n",
    "\n",
    "Of course there is a lot of small print to that. I won't go over it since it is very mathsy and I prefer to show you how it works. You can read it in this [quantecon lecture](https://lectures.quantecon.org/py/optgrowth.html), upon whom our exercise today is based.\n",
    "\n",
    "I'll explain the basics with an example:\n",
    "\n",
    "## A Deterministic Growth problem\n",
    "\n",
    "The problem we want to solve is the following:\n",
    "\n",
    "$$V(k) = \\max_c u(c) + \\beta V(k') $$\n",
    "st\n",
    "$$ c + k' = k^\\alpha $$\n",
    "\n",
    "Where $u(.)$ is our utility function, $c$ is consumption, $k$ is capital, $\\alpha$ is a parameter of the production function and $\\beta$ the discount rate. There is full depreciation. Variables next period are denoted with '\n",
    "\n",
    "So how do we solve this? Well, we know that when we find the solution wue will be able to evaluate the right hand side of the bellman, obtaining a value for the *optimal* value function ($V^*$). In that case, it must be true that\n",
    "\n",
    "$$V^*(k) = u(c^*) + \\beta V^*(k') $$\n",
    "\n",
    "So whatever decision we made about today it must be optimal for tomorrow too. Think about $V$ as a number for a second. We could start by setting $V_0=1$ (or any other number) and then calculate\n",
    "\n",
    "$$\\max_{k'} u(k^\\alpha-k') + \\beta V_0$$\n",
    "\n",
    "Where I have substituted consumption from the budget/feasibility constraint. Call this value $V_1$, the value function that results from \"guessing\" $V_0$ is the answer. Of course, the most likely case is that $V_1\\neq V_0$, so pur guess won't be the right answer.\n",
    "\n",
    "But here comes the magic: if we repeat the process inserting $V_1$ as our new guess, and we keep repeating it, it will come to a point where $V_{n+1}= V_{n}$, so we would have found the optimal $V^*$ as we defined it above. If certain regulatity conditions are met - close, bounded space for $c$ and $V$, $u(.)$ is continous and concave etc. (I refer to you to the [quantecon lecture](https://lectures.quantecon.org/py/optgrowth.html) or any book on computational economics) then this algorithm is sure to converge. It is so powerful, it usually converges when we don't have a proof that it will - so we are not guaranteed to find an answer!\n",
    "\n",
    "###Â Discretizing the space\n",
    "\n",
    "However, you may ahve noticed that $V(k)$ is a function and I have been treating it like a number. There are different ways to deal with $V()$ and $c()$, but all of them require us to discretize the space somehow. The easiest and crudest way of doing it is to create a vector (grid) of possible capital stocks $k$, and let $max_{k'}$ mean \"the best possible capital in the grid\". This will give us a map $k\\rightarrow k'$ (capital today to capital tomorrow) that would be our function.\n",
    "\n",
    "Finally, let's set $u(c)=log(c)$. At this point you should know why :)\n",
    "\n",
    "Let's see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining Parameters (feel free to change)\n",
    "alpha = 0.65\n",
    "beta = 0.95\n",
    "\n",
    "# Defining grid for capital\n",
    "grid_max = 2\n",
    "grid_size = 150\n",
    "grid = np.linspace(1e-6, grid_max, grid_size) # you can plot it or print it to see it. It is good practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this special case, we can get the solution with pen and pencil as you did in this course: the solution takes the form:\n",
    "\n",
    "$$V^*(k) = \\gamma_1 + \\gamma_2 log(k) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\gamma_2=\\frac{\\alpha}{(1-\\alpha\\beta)}$$\n",
    "$$\\gamma_1= \\frac{log(1 - \\alpha\\beta) + log(\\alpha\\beta) * \\frac{\\alpha\\beta}{(1 - \\alpha\\beta)}} {(1 - \\beta)}$$\n",
    "\n",
    "> **Task 1:** code the exact answer: define two variables for $\\gamma_1$ and $\\gamma_2$ and a function for the optimal value function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exact solution (for comparison)\n",
    "ab = alpha * beta   # This should help you\n",
    "g2 = # Code here\n",
    "g1 = # Code here (tip: natural logs are np.log())\n",
    "\n",
    "def v_star(k):\n",
    "    return # Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Bellman operator\n",
    "\n",
    "Here is the code for *the bellman operator*, or the function that given a initial guess for the value function $w$ returns $Tw$, the next guess. It obtains the next guess by computing the optimal capital for all points of the capital grid, given value function for tomorrow $V(k')=w$. \n",
    "\n",
    "To calculate the optimal $a'$, it uses a function called [fminbound](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fminbound.html), which if you did the Christmas exercises you should be familiar with. Or at least know that is is an optimizer function similar ``fsolve`` in Matlab. For some technical reason, it is easier to find the minimun rather than the maximun.\n",
    "\n",
    "Another function you want to check is [interp](https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html), which interpolates a series of points $x = x_1,x_2,...$,$y = y_1,y_2,...$ as if it was \"joining the dots\" between them, thereby constructing a function $f(x)=y$. We will use it to generate the next guess: given an initial guess for the value function $V$ and a grid for capital $k$, it interpolates so to get $V(k)$. This way, we just need a series of values for V, not an entire function!\n",
    "\n",
    "> **Task 2:** Read the code below, ask questions if you get lost, and make sure you udnerstand what it does. You can try out pieces of the code (say ```interp(x, xs, ys)```) in a separate cell to help you digest the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bellman_operator(w):\n",
    "    \"\"\"\n",
    "    The approximate Bellman operator, which computes and returns the updated\n",
    "    value function Tw on the grid points.\n",
    "\n",
    "        * w is a flat NumPy array with len(w) = len(grid)\n",
    "\n",
    "    The vector w represents the value of the input function on the grid\n",
    "    points.\n",
    "    \"\"\"\n",
    "    # For a set of w=v(k), link the points such that we get a function w(k)\n",
    "    Aw = lambda x: interp(x, grid, w)\n",
    "    \n",
    "    # Generate our next guess:\n",
    "    Tw = np.empty(grid_size)                                         # Create space for our new guess, w'\n",
    "    for i, k in enumerate(grid):                                     # for each index and value of k in out grid: \n",
    "        objective = lambda c: - log(c) - beta * Aw(k**alpha - c)     # define the objective function (in one line)\n",
    "        c_star = fminbound(objective, 1e-6, k**alpha)                # find the optimal c* that max. u(c) + beta w(k'(c))\n",
    "        Tw[i] = - objective(c_star)                                  # store the values for our v(c*) => w'\n",
    "\n",
    "    return Tw                                                        # Return those values as our new w'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the function!\n",
    "\n",
    "> **Task 3**: Call the bellman operator function, then plor the result and the initial guess provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Roll the bellman operator once\n",
    "w0 = 5 * log(grid) - 25 # initial guess\n",
    "w1 = # Call the bellman operator function\n",
    "\n",
    "# Plot\n",
    "plt.plot(#code the initial guess here, label='initial guess')\n",
    "plt.plot(#code the second guess here, c='blue', alpha=0.7, ls='--', label='1 iteration')\n",
    "plt.ylabel('$w(a_i)$', fontsize=16)\n",
    "plt.xlabel('$a_i$', fontsize=16)\n",
    "plt.title('One step Beyond', fontsize=16)\n",
    "plt.ylim(-40, -20)\n",
    "plt.legend(loc='best', frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep rolling! The resulting plot shows the convergence of the value function to the true one.\n",
    "\n",
    "> **Task 4:** Fill in the blanks below to produce a rainbow plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 35       # number of steps\n",
    "\n",
    "# Plot configuration\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.ylim(-40, -20)\n",
    "plt.xlim(np.min(grid), np.max(grid))\n",
    "plt.plot(grid, w0, color=plt.cm.jet(0), lw=2, alpha=0.6, label='initial guess')\n",
    "\n",
    "# Bellman\n",
    "w = # initial guess here\n",
    "for i in range(n):\n",
    "    w = # update the bellman\n",
    "    plt.plot(grid, w, color=plt.cm.jet(i / n), lw=2, alpha=0.6)\n",
    "\n",
    "# True value function\n",
    "plt.plot(# plot the true value function here, 'k-', lw=2, alpha=0.8, label='true value function')\n",
    "\n",
    "# Final touches\n",
    "plt.legend(loc='upper left', frameon='True')\n",
    "plt.title('Rolling on!', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to solve our problem, we just need to keep going until convergence. Because we are using an approximation (gridpoints are finite, the solution (a function) is infinite) it won't be the case that $V_{n+1}=V_n$, so we need to stablish a *close enough* parameter we cal *tolerance* (or ```tol```).\n",
    "\n",
    "Execute the cell below to solve the problem. \n",
    "\n",
    "Make sure you read and understand the steps - you can make comments on the side to remember what each piece of code does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keep on going until convergence\n",
    "\n",
    "w = w0\n",
    "tol = 1e-6\n",
    "distance = np.abs(np.max(w0 - bellman_operator(w0)))\n",
    "iterations = 0\n",
    "while distance > tol:\n",
    "    w_next = bellman_operator(w)\n",
    "    distance = np.abs(np.max(w - w_next))\n",
    "    w = w_next\n",
    "    iterations += 1\n",
    "    if iterations % 50 == 0:\n",
    "        print ' after {} iterations, distance is {}'.format(iterations, distance)\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the result! \n",
    "\n",
    "Again, read and make sure you understand the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the result\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(grid, w0, label='initial guess')\n",
    "plt.plot(grid, w, c='blue', alpha=0.7, ls='--', label='iteration #{}'.format(iterations))\n",
    "plt.plot(grid, v_star(grid), 'k-', lw=2, alpha=0.5, label='true value function')\n",
    "\n",
    "plt.ylim(-40, -20)\n",
    "plt.ylabel('$w(a_i)$', fontsize=16)\n",
    "plt.xlabel('$a_i$', fontsize=16)\n",
    "plt.title('Convergence', fontsize=16)\n",
    "plt.legend(loc='best', frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We did it!\n",
    "\n",
    "## 3. Solving for the optimal policy function\n",
    "\n",
    "Just as we solved for $V$, it would be great if we could also know what is the optimal $c$ for each asset - so we can know the optimal savings.\n",
    "\n",
    "To do that we just need to add a little tweek in the code.\n",
    "\n",
    "> **Task 5** Read the code below. Can you find the differences with ```bellman_operator``` above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bellman_operator_plus(w, return_policy=False, grid=np.linspace(1e-6, 2, 150), u=lambda x: log(x)):\n",
    "    \"\"\"\n",
    "    The approximate Bellman operator, which computes and returns the updated\n",
    "    value function Tw on the grid points.\n",
    "    Inputs:\n",
    "        * w is a flat NumPy array with len(w) = len(grid)\n",
    "        * return_policy is a boolean, if true returns w (value) and c (optimal policy)\n",
    "        * grid is a NumPy array with one-dimensional vector of state points\n",
    "        * u is a function with a single numerical argument: instantaneous utility function\n",
    "\n",
    "    Returns:\n",
    "        * w  - and if return_policy==True, a tuple (w,c)\n",
    "    \"\"\"\n",
    "    # For a set of w=v(a), link the points such that we get a function w(a)\n",
    "    Aw = lambda x: interp(x, grid, w)\n",
    "    \n",
    "    # Generate our next guess:\n",
    "    Tw = np.empty(grid_size)                                         # Create space for our new guess, w'\n",
    "    policy = np.empty(grid_size)\n",
    "    for i, k in enumerate(grid):                                     # for each index and value of k in out grid: \n",
    "        objective = lambda c: - u(c) - beta * Aw(k**alpha - c)     # define the objective function (in one line)\n",
    "        c_star = fminbound(objective, 1e-6, k**alpha)                # find the optimal c* that max. u(c) + beta w(a'(c))\n",
    "        Tw[i] = - objective(c_star)                                  # store the values for our v(c*) => w'\n",
    "        policy[i] = c_star                                           # store the values for our c*\n",
    "    # Return time\n",
    "    if return_policy==False:\n",
    "        return Tw                                                    # Return those values as our new w'\n",
    "    else:\n",
    "        return (Tw,policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run this function and solve the problem again\n",
    "\n",
    "> **Task 6**: Fill in the blanks below - if you understood the function above it should be a pieve of cake!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = w0\n",
    "tol = 1e-6\n",
    "distance = np.abs(np.max(w0 - bellman_operator(w0)))\n",
    "iterations = 0\n",
    "while distance > tol:\n",
    "    bellman = bellman_operator_plus(w, return_policy=True)\n",
    "    w_next = # pick the right one here\n",
    "    policy = # pick the right one here\n",
    "    distance = np.abs(np.max(w - w_next))\n",
    "    w = w_next\n",
    "    iterations += 1\n",
    "    if iterations % 50 == 0:\n",
    "        print ' after {} iterations, distance is {}'.format(iterations, distance)\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tru optimal consumption - from your notes. An evil macro teacher would tell you to find it yourself!\n",
    "true_c = (1 - alpha * beta) * grid**alpha\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(grid,policy, label='Our $c^*(a_i)$')\n",
    "plt.plot(grid,true_c, color='black', alpha=0.5, label='True $c^*(a_i)$')\n",
    "plt.title('Policy function', fontsize=18)\n",
    "plt.xlabel('$a_i$', fontsize=16)\n",
    "plt.ylabel('$c^*(a_i)$', fontsize=16)\n",
    "plt.legend(loc='best',fontsize=16, frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Zoom in\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(grid,policy, label='Our $c^*(a_i)$')\n",
    "plt.plot(grid,true_c, color='black', alpha=0.5, label='True $c^*(a_i)$')\n",
    "plt.title('Policy function (zoom around 1)', fontsize=18)\n",
    "plt.xlabel('$a_i$', fontsize=16)\n",
    "plt.ylabel('$c^*(a_i)$', fontsize=16)\n",
    "plt.xlim(0.8,1.2)\n",
    "plt.ylim(0.3,0.45)\n",
    "plt.legend(loc='best',fontsize=16, frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Finito\n",
    "\n",
    "As you can see, the answer is just approximate - because of the discretization. There are more fancy ways of doing it, but I'll leave that for another time.\n",
    "\n",
    "For now, you can play around with ```bellman_operator_plus```: try different utility functions, parameters, etc. It is nice to see the difference between logs, CRRA and quadratic utility for example.\n",
    "\n",
    "Make sure you understand the logic of the algorithm. Next week we'll do something more interesting: a consumption/growth problem with uncertainty - first stochastic growth (white noise shocks) and then markow chain (the innovation tomorrow can be approximated from the innovation today)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
